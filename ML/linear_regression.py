# -*- coding: utf-8 -*-
"""Linear Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10QdV_5Qb_20RkwTcvUh7EZGZdNybAwIK
"""

'''
Linear Regression with Gradient Descent
'''



import numpy as np
import os
import pandas as pd
import seaborn as sns
from scipy.stats import entropy
import matplotlib.pyplot as plt
from tqdm import tqdm

from google.colab import files
uploaded = files.upload()

df = pd.read_csv('housing_data.csv')
df.head()
df.columns

hd = df[['area', 'price']]
hd.head()

#Standardize the dataset
mean = np.array(hd.mean())
print(mean)

std = np.array(hd.std())
print(std)

hd = (hd-mean)/std
print(hd)

sns.relplot(
    data = hd,
    x='area',
    y='price'
)

'''
Objective: Make a random linear predictor

y = mx + c
m = slope
c = intersect


For our problem,
predicted price = w*area + b
w = weight
b = bias

w, b => parameters
'''

def get_house_price(x, w, b):
  y_pred = w * x +b
  return y_pred



w = np.random.randint(100,200)
b = np.random.randint(100,200)

print(w, b)

hd["price_pred_rand"]= get_house_price(hd['area'], w, b)

hd.head()

'''
ML Learning Algorithm
1. Maximize likelihood between true distribution and predicted distribution
Alternately, minimizing the KL divergence
Alternately, minimizing loss/cost function

We will use mean squared error as our cost function
'''

def cost_function(x, yhat, w,b):
  y_pred = get_house_price(y_true, w, b)
  mse = np.mean((y_true-y_pred)**2)/2
  return mse

x = hd['area']
y_true = hd['price']


loss = cost_function(x, y_true, w, b)
print(loss)

loss1 = cost_function(x, y_true, 100, 125)
print(loss1)
loss2 = cost_function(x, y_true, 120, 185)
print(loss2)
loss3 = cost_function(x, y_true, 112, 169)
print(loss3)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load dataset
df = pd.read_csv('housing_data.csv')

# Use 'area' as input (X) and 'price' as output (y)
X = df['area'].values
y = df['price'].values

# Normalize features (important for gradient descent convergence)
X = (X - np.mean(X)) / np.std(X)

# Initialize parameters
w = 0
b = 0
learning_rate = 0.01
epochs = 1000
n = len(X)

# Store loss history
loss_history = []

# Gradient Descent Loop
for epoch in range(epochs):
    y_pred = w * X + b
    error = y_pred - y

    # Gradients
    dw = (2/n) * np.dot(error, X)
    db = (2/n) * np.sum(error)

    # Update weights
    w -= learning_rate * dw
    b -= learning_rate * db

    # Loss (MSE)
    loss = np.mean(error ** 2)
    loss_history.append(loss)

    # Print every 100 epochs
    if epoch % 100 == 0:
        print(f"Epoch {epoch}: Loss = {loss:.2f}")

# Plot Loss Curve
plt.plot(loss_history)
plt.title("Loss During Training")
plt.xlabel("Epoch")
plt.ylabel("MSE")
plt.show()

print(f"Final model: price = {w:.2f} * area + {b:.2f}")

plt.scatter(X, y, label='Actual')
plt.plot(X, w * X + b, color='red', label='Prediction')
plt.title("Linear Regression Fit")
plt.xlabel("Normalized Area")
plt.ylabel("Price")
plt.legend()
plt.show()